{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Kolada Data\n",
    "\n",
    "This notebook fetches actual data values from the Kolada API for specified KPIs, municipalities, and years.\n",
    "\n",
    "**API Endpoints:**\n",
    "- `http://api.kolada.se/v2/data/kpi/{kpi}/municipality/{municipality}/year/{year}`\n",
    "- `http://api.kolada.se/v2/oudata/kpi/{kpi}/ou/{ou}/year/{year}`\n",
    "\n",
    "**Parameters to customize:**\n",
    "- KPI IDs (comma-separated)\n",
    "- Municipality IDs (comma-separated)\n",
    "- Years (comma-separated)\n",
    "\n",
    "**Output:** Kolada data tables in Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "API_BASE_URL = \"http://api.kolada.se/v2\"\n",
    "PER_PAGE = 5000\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# Default years\n",
    "YEARS = [str(y) for y in range(2010, 2026)]\n",
    "OU_YEARS = [str(y) for y in range(2010, 2026)]\n",
    "\n",
    "# Read all KPI IDs from Lakehouse\n",
    "df_kpi_dim = spark.table(\"dKpi\").toPandas()\n",
    "KPI_IDS = df_kpi_dim[\"id\"].tolist()\n",
    "print(f\"Loaded {len(KPI_IDS)} KPIs from dKpi\")\n",
    "\n",
    "# Filter OU KPIs (has_ou_data == True or 1)\n",
    "OU_KPI_IDS = df_kpi_dim[df_kpi_dim[\"has_ou_data\"] == 1][\"id\"].tolist()\n",
    "print(f\"Loaded {len(OU_KPI_IDS)} OU KPIs from dKpi\")\n",
    "\n",
    "# Leave empty for all municipalities/OUs\n",
    "MUNICIPALITY_IDS = []\n",
    "OU_IDS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data_paginated(url: str) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Fetch data from Kolada API with pagination support.\n",
    "    \n",
    "    Args:\n",
    "        url: Initial API URL\n",
    "        \n",
    "    Returns:\n",
    "        List of data objects\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    page_count = 0\n",
    "    \n",
    "    while url:\n",
    "        try:\n",
    "            response = requests.get(url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            \n",
    "            if 'values' in data:\n",
    "                all_data.extend(data['values'])\n",
    "                page_count += 1\n",
    "                print(f\"  Page {page_count}: Retrieved {len(data['values'])} items (Total: {len(all_data)})\")\n",
    "            \n",
    "            # Check for next page\n",
    "            url = data.get('next_page', None)\n",
    "            \n",
    "            # Be nice to the API\n",
    "            if url:\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"  Error fetching data: {e}\")\n",
    "            break\n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_kolada_data(kpi_ids: List[str], municipality_ids: Optional[List[str]], years: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch Kolada data for specified parameters.\n",
    "    \n",
    "    Args:\n",
    "        kpi_ids: List of KPI IDs\n",
    "        municipality_ids: List of municipality IDs (None for all)\n",
    "        years: List of years\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with all fetched data\n",
    "    \"\"\"\n",
    "    all_records = []\n",
    "    \n",
    "    # Build URL based on parameters\n",
    "    kpi_param = ','.join(kpi_ids)\n",
    "    year_param = ','.join(years)\n",
    "    \n",
    "    if municipality_ids and len(municipality_ids) > 0:\n",
    "        municipality_param = ','.join(municipality_ids)\n",
    "        url = f\"{API_BASE_URL}/data/kpi/{kpi_param}/municipality/{municipality_param}/year/{year_param}?per_page={PER_PAGE}\"\n",
    "    else:\n",
    "        url = f\"{API_BASE_URL}/data/kpi/{kpi_param}/year/{year_param}?per_page={PER_PAGE}\"\n",
    "    \n",
    "    print(f\"Fetching data from: {url}\")\n",
    "    \n",
    "    data = fetch_data_paginated(url)\n",
    "    \n",
    "    # Flatten the data structure\n",
    "    for item in data:\n",
    "        kpi = item.get('kpi')\n",
    "        municipality = item.get('municipality')\n",
    "        period = item.get('period')\n",
    "        \n",
    "        # Each item can have multiple values (by gender)\n",
    "        if 'values' in item:\n",
    "            for value_item in item['values']:\n",
    "                record = {\n",
    "                    'kpi': kpi,\n",
    "                    'municipality': municipality,\n",
    "                    'period': period,\n",
    "                    'gender': value_item.get('gender'),\n",
    "                    'value': value_item.get('value'),\n",
    "                    'count': value_item.get('count'),\n",
    "                    'status': value_item.get('status'),\n",
    "                    'ingestion_timestamp': datetime.now(),\n",
    "                    'source_system': 'Kolada API',\n",
    "                    'ou_id': f\"NO_OU_{municipality}\",  # Placeholder for municipality-level data\n",
    "                }\n",
    "                all_records.append(record)\n",
    "    \n",
    "    if all_records:\n",
    "        return pd.DataFrame(all_records)\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ou_data(kpi_ids: List[str], ou_ids: Optional[List[str]], years: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch Kolada organizational unit data for specified parameters.\n",
    "    \n",
    "    Args:\n",
    "        kpi_ids: List of KPI IDs\n",
    "        ou_ids: List of OU IDs (None for all)\n",
    "        years: List of years\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with all fetched data\n",
    "    \"\"\"\n",
    "    all_records = []\n",
    "    \n",
    "    # Build URL based on parameters\n",
    "    kpi_param = ','.join(kpi_ids)\n",
    "    year_param = ','.join(years)\n",
    "    \n",
    "    if ou_ids and len(ou_ids) > 0:\n",
    "        ou_param = ','.join(ou_ids)\n",
    "        url = f\"{API_BASE_URL}/oudata/kpi/{kpi_param}/ou/{ou_param}/year/{year_param}?per_page={PER_PAGE}\"\n",
    "    else:\n",
    "        url = f\"{API_BASE_URL}/oudata/kpi/{kpi_param}/year/{year_param}?per_page={PER_PAGE}\"\n",
    "    \n",
    "    print(f\"Fetching OU data from: {url}\")\n",
    "    \n",
    "    data = fetch_data_paginated(url)\n",
    "    \n",
    "    # Flatten the data structure\n",
    "    for item in data:\n",
    "        kpi = item.get('kpi')\n",
    "        ou = item.get('ou')\n",
    "        period = item.get('period')\n",
    "        \n",
    "        # Each item can have multiple values (by gender)\n",
    "        if 'values' in item:\n",
    "            for value_item in item['values']:\n",
    "                record = {\n",
    "                    'kpi': kpi,\n",
    "                    'ou_id': ou,\n",
    "                    'municipality': None,  # Will be looked up from dOrganizationalUnit\n",
    "                    'period': period,\n",
    "                    'gender': value_item.get('gender'),\n",
    "                    'value': value_item.get('value'),\n",
    "                    'count': value_item.get('count'),\n",
    "                    'status': value_item.get('status'),\n",
    "                    'ingestion_timestamp': datetime.now(),\n",
    "                    'source_system': 'Kolada API'\n",
    "                }\n",
    "                all_records.append(record)\n",
    "    \n",
    "    if all_records:\n",
    "        return pd.DataFrame(all_records)\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch municipality data in batches\n",
    "print(\"=\"*60)\n",
    "print(\"Fetching Municipality Data\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total KPIs: {len(KPI_IDS)}\")\n",
    "print(f\"Municipalities: {MUNICIPALITY_IDS if MUNICIPALITY_IDS else 'All'}\")\n",
    "print(f\"Years: {YEARS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print()\n",
    "\n",
    "# Check what's already been fetched\n",
    "try:\n",
    "    df_existing = spark.table(\"fKoladaData\").select(\"kpi\").distinct().toPandas()\n",
    "    fetched_kpis = set(df_existing[\"kpi\"].tolist())\n",
    "    print(f\"Already fetched {len(fetched_kpis)} KPIs in fKoladaData\")\n",
    "except:\n",
    "    fetched_kpis = set()\n",
    "    print(\"No existing fKoladaData table found, starting fresh\")\n",
    "\n",
    "# Filter out already-fetched KPIs\n",
    "remaining_kpis = [k for k in KPI_IDS if k not in fetched_kpis]\n",
    "print(f\"Remaining KPIs to fetch: {len(remaining_kpis)} of {len(KPI_IDS)}\")\n",
    "\n",
    "for i in range(0, len(remaining_kpis), BATCH_SIZE):\n",
    "    batch = remaining_kpis[i:i+BATCH_SIZE]\n",
    "    print(f\"\\nBatch {i//BATCH_SIZE + 1}: Fetching {len(batch)} KPIs ({batch[:3]}...)\")\n",
    "    \n",
    "    df_batch = fetch_kolada_data(batch, MUNICIPALITY_IDS if MUNICIPALITY_IDS else None, YEARS)\n",
    "    \n",
    "    if not df_batch.empty:\n",
    "        spark_df = spark.createDataFrame(df_batch)\n",
    "        spark_df.write.mode(\"append\").format(\"delta\").saveAsTable(\"fKoladaData\")\n",
    "        print(f\"  \u2713 Wrote {len(df_batch)} rows to fKoladaData\")"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Organizational Unit Data\n",
    "\n",
    "OU data is now enabled by default and will be merged with municipality data into a unified fact table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch OU data in batches\n",
    "print(\"=\"*60)\n",
    "print(\"Fetching Organizational Unit Data\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total OU KPIs: {len(OU_KPI_IDS)}\")\n",
    "print(f\"OUs: {OU_IDS if OU_IDS else 'All'}\")\n",
    "print(f\"Years: {OU_YEARS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print()\n",
    "\n",
    "# Check which OU KPIs have already been fetched\n",
    "try:\n",
    "    df_existing_ou = (\n",
    "        spark.table(\"fKoladaData\")\n",
    "        .filter(\"ou_id NOT LIKE 'NO_OU_%'\")\n",
    "        .select(\"kpi\").distinct().toPandas()\n",
    "    )\n",
    "    fetched_ou_kpis = set(df_existing_ou[\"kpi\"].tolist())\n",
    "    print(f\"Already fetched {len(fetched_ou_kpis)} OU KPIs\")\n",
    "except:\n",
    "    fetched_ou_kpis = set()\n",
    "    print(\"No existing OU data found\")\n",
    "\n",
    "remaining_ou_kpis = [k for k in OU_KPI_IDS if k not in fetched_ou_kpis]\n",
    "print(f\"Remaining OU KPIs to fetch: {len(remaining_ou_kpis)} of {len(OU_KPI_IDS)}\")\n",
    "\n",
    "# Load OU-to-municipality lookup once\n",
    "try:\n",
    "    df_ou_dim = spark.table(\"dOrganizationalUnit\").toPandas()\n",
    "    ou_to_muni = df_ou_dim.set_index('id')['municipality'].to_dict()\n",
    "except:\n",
    "    ou_to_muni = {}\n",
    "    print(\"\u26a0 Could not load dOrganizationalUnit for municipality lookup\")\n",
    "\n",
    "for i in range(0, len(remaining_ou_kpis), BATCH_SIZE):\n",
    "    batch = remaining_ou_kpis[i:i+BATCH_SIZE]\n",
    "    print(f\"\\nBatch {i//BATCH_SIZE + 1}: Fetching {len(batch)} OU KPIs ({batch[:3]}...)\")\n",
    "    \n",
    "    df_batch = fetch_ou_data(batch, OU_IDS if OU_IDS else None, OU_YEARS)\n",
    "    \n",
    "    if not df_batch.empty:\n",
    "        if ou_to_muni:\n",
    "            df_batch['municipality'] = df_batch['ou_id'].map(ou_to_muni)\n",
    "        \n",
    "        spark_df = spark.createDataFrame(df_batch)\n",
    "        spark_df.write.mode(\"append\").format(\"delta\").saveAsTable(\"fKoladaData\")\n",
    "        print(f\"  \u2713 Wrote {len(df_batch)} rows to fKoladaData\")"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add surrogate keys from dimension tables (post-processing)\n",
    "try:\n",
    "    df_fact = spark.table(\"fKoladaData\").toPandas()\n",
    "    \n",
    "    if not df_fact.empty:\n",
    "        print(\"\\nAdding surrogate keys...\")\n",
    "        \n",
    "        # Check if surrogate keys already exist\n",
    "        has_keys = all(col in df_fact.columns for col in ['kpi_key', 'municipality_key', 'ou_key'])\n",
    "        \n",
    "        if not has_keys:\n",
    "            # Load dimension tables\n",
    "            df_kpi_dim = spark.table(\"dKpi\").toPandas()\n",
    "            df_muni_dim = spark.table(\"dMunicipality\").toPandas()\n",
    "            df_ou_dim = spark.table(\"dOrganizationalUnit\").toPandas()\n",
    "            \n",
    "            # Create lookup dictionaries\n",
    "            kpi_lookup = df_kpi_dim.set_index('id')['kpi_key'].to_dict()\n",
    "            muni_lookup = df_muni_dim.set_index('id')['municipality_key'].to_dict()\n",
    "            ou_lookup = df_ou_dim.set_index('id')['ou_key'].to_dict()\n",
    "            \n",
    "            # Add surrogate keys\n",
    "            df_fact['kpi_key'] = df_fact['kpi'].map(kpi_lookup)\n",
    "            df_fact['municipality_key'] = df_fact['municipality'].map(muni_lookup)\n",
    "            df_fact['ou_key'] = df_fact['ou_id'].map(ou_lookup)\n",
    "            \n",
    "            print(f\"  \u2713 Added kpi_key (matched {df_fact['kpi_key'].notna().sum()}/{len(df_fact)} rows)\")\n",
    "            print(f\"  \u2713 Added municipality_key (matched {df_fact['municipality_key'].notna().sum()}/{len(df_fact)} rows)\")\n",
    "            print(f\"  \u2713 Added ou_key (matched {df_fact['ou_key'].notna().sum()}/{len(df_fact)} rows)\")\n",
    "            \n",
    "            # Write back with overwrite to replace with enriched data\n",
    "            spark_df = spark.createDataFrame(df_fact)\n",
    "            spark_df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"fKoladaData\")\n",
    "            print(f\"\\n\u2713 Updated fKoladaData with surrogate keys\")\n",
    "        else:\n",
    "            print(\"  Surrogate keys already exist, skipping enrichment\")\n",
    "    else:\n",
    "        print(\"No data in fKoladaData table\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  \u26a0 Could not add surrogate keys: {e}\")\n",
    "    print(\"  Make sure notebooks 01 and 02 have been run to create dimension tables\")"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality summary for unified fact table\n",
    "try:\n",
    "    df_fact = spark.table(\"fKoladaData\").toPandas()\n",
    "    \n",
    "    if not df_fact.empty:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"UNIFIED FACT TABLE SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(f\"\\nTotal data points: {len(df_fact)}\")\n",
    "        \n",
    "        # Count by data source (based on ou_id pattern)\n",
    "        municipality_count = df_fact['ou_id'].str.startswith('NO_OU_').sum()\n",
    "        ou_count = len(df_fact) - municipality_count\n",
    "        print(f\"\\nData points by source:\")\n",
    "        print(f\"  Municipality-level: {municipality_count}\")\n",
    "        print(f\"  OU-level: {ou_count}\")\n",
    "        \n",
    "        print(f\"\\nData points by KPI:\")\n",
    "        print(df_fact['kpi'].value_counts())\n",
    "        \n",
    "        print(f\"\\nData points by period:\")\n",
    "        print(df_fact['period'].value_counts().sort_index())\n",
    "        \n",
    "        print(f\"\\nData points by gender:\")\n",
    "        print(df_fact['gender'].value_counts())\n",
    "        \n",
    "        print(f\"\\nNull values in value column:\")\n",
    "        print(df_fact['value'].isnull().sum(), \"out of\", len(df_fact))\n",
    "        \n",
    "        # Check if surrogate keys exist\n",
    "        if 'kpi_key' in df_fact.columns:\n",
    "            print(f\"\\nSurrogate key coverage:\")\n",
    "            print(f\"  kpi_key: {df_fact['kpi_key'].notna().sum()}/{len(df_fact)}\")\n",
    "            print(f\"  municipality_key: {df_fact['municipality_key'].notna().sum()}/{len(df_fact)}\")\n",
    "            print(f\"  ou_key: {df_fact['ou_key'].notna().sum()}/{len(df_fact)}\")\n",
    "        \n",
    "        print(\"\\nSample of unified fact table:\")\n",
    "        display(df_fact.head(10))\n",
    "    else:\n",
    "        print(\"No data in fKoladaData table\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not load fKoladaData table: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}