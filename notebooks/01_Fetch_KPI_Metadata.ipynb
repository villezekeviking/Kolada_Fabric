{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fetch KPI Metadata from Kolada API\n",
        "\n",
        "This notebook fetches all KPI (Key Performance Indicator) metadata from the Kolada API and stores it in the Lakehouse.\n",
        "\n",
        "**API Endpoint:** `http://api.kolada.se/v2/kpi`\n",
        "\n",
        "**Output:** KPI metadata table in Lakehouse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "API_BASE_URL = \"http://api.kolada.se/v2\"\n",
        "ENDPOINT = \"kpi\"\n",
        "PER_PAGE = 5000\n",
        "\n",
        "# Lakehouse table name\n",
        "TABLE_NAME = \"kpi_metadata\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_all_kpi_metadata():\n",
        "    \"\"\"\n",
        "    Fetch all KPI metadata from Kolada API with pagination support.\n",
        "    \n",
        "    Returns:\n",
        "        list: List of all KPI metadata objects\n",
        "    \"\"\"\n",
        "    all_data = []\n",
        "    url = f\"{API_BASE_URL}/{ENDPOINT}?per_page={PER_PAGE}\"\n",
        "    \n",
        "    page_count = 0\n",
        "    \n",
        "    while url:\n",
        "        try:\n",
        "            print(f\"Fetching page {page_count + 1}...\")\n",
        "            response = requests.get(url, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            \n",
        "            data = response.json()\n",
        "            \n",
        "            if 'values' in data:\n",
        "                all_data.extend(data['values'])\n",
        "                print(f\"  Retrieved {len(data['values'])} KPIs (Total: {len(all_data)})\")\n",
        "            \n",
        "            # Check for next page\n",
        "            url = data.get('next_page', None)\n",
        "            page_count += 1\n",
        "            \n",
        "            # Be nice to the API\n",
        "            if url:\n",
        "                time.sleep(0.5)\n",
        "                \n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching data: {e}\")\n",
        "            break\n",
        "    \n",
        "    print(f\"\\nTotal KPIs fetched: {len(all_data)}\")\n",
        "    return all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fetch KPI metadata\n",
        "print(\"Starting KPI metadata fetch...\")\n",
        "print(f\"API URL: {API_BASE_URL}/{ENDPOINT}\")\n",
        "print(f\"Timestamp: {datetime.now()}\\n\")\n",
        "\n",
        "kpi_data = fetch_all_kpi_metadata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to DataFrame\n",
        "if kpi_data:\n",
        "    df_kpi = pd.DataFrame(kpi_data)\n",
        "    \n",
        "    # Add metadata columns\n",
        "    df_kpi['ingestion_timestamp'] = datetime.now()\n",
        "    df_kpi['source_system'] = 'Kolada API'\n",
        "    \n",
        "    print(f\"DataFrame shape: {df_kpi.shape}\")\n",
        "    print(f\"\\nColumn names: {list(df_kpi.columns)}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    display(df_kpi.head())\n",
        "else:\n",
        "    print(\"No data retrieved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write to Lakehouse (Delta table)\n",
        "if kpi_data:\n",
        "    spark_df = spark.createDataFrame(df_kpi)\n",
        "    spark_df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(TABLE_NAME)\n",
        "    \n",
        "    print(f\"\\n\u2713 Successfully wrote {len(df_kpi)} KPIs to {TABLE_NAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics\n",
        "if kpi_data:\n",
        "    print(\"\\n=== Summary Statistics ===\")\n",
        "    print(f\"Total KPIs: {len(df_kpi)}\")\n",
        "    print(f\"\\nKPIs by municipality type:\")\n",
        "    print(df_kpi['municipality_type'].value_counts())\n",
        "    print(f\"\\nKPIs divided by gender:\")\n",
        "    print(df_kpi['is_divided_by_gender'].value_counts())\n",
        "    print(f\"\\nKPIs with OU data:\")\n",
        "    print(df_kpi['has_ou_data'].value_counts())"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}